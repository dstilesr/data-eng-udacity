# Sparkify Data Lake

## Contents

* [About](#about)
* [Repository Contents](#repository-contents)
* [Output Data Organization](#output-data-organization)
* [Running the Project](#running-the-project)

## About
The purpose of this project is to create an etl pipeline using
[Spark](https://spark.apache.org/) in order to prepare raw song and log data
for analytics. The raw data in JSON format will be read from S3, processed on a
Spark cluster and the results will be stored back to S3 as Parquet files. The
processed data will be organized as a star schema to facilitate analytics.

## Repository Contents


## Output Data Organization


## Running the Project


[Back to top](#sparkify-data-lake)
